"""
Qwen3-Embedding-0.6B æ¨¡å‹è·¯å¾„æ¢ç´¢æµ‹è¯•

è¿™ä¸ªæµ‹è¯•æ–‡ä»¶ç”¨äºéªŒè¯Qwen3-Embedding-0.6Bæ¨¡å‹æ˜¯å¦èƒ½å¤Ÿæ›¿ä»£å½“å‰çš„jina-embeddings-v2-base-codeæ¨¡å‹ã€‚
æµ‹è¯•å†…å®¹åŒ…æ‹¬ï¼š
1. æ¨¡å‹åŠ è½½å’ŒåŸºæœ¬åŠŸèƒ½éªŒè¯
2. æ€§èƒ½å¯¹æ¯”æµ‹è¯•
3. ä¸ç°æœ‰ç³»ç»Ÿçš„å…¼å®¹æ€§æµ‹è¯•
4. ä»£ç åµŒå…¥è´¨é‡è¯„ä¼°

æµ‹è¯•ç›®æ ‡ï¼šä¸ºæ¨¡å‹æ›¿æ¢å†³ç­–æä¾›æ•°æ®æ”¯æŒ
"""

import pytest
import numpy as np
import time
import os
from typing import List, Dict, Any, Tuple
from dataclasses import dataclass

# å°è¯•å¯¼å…¥æ‰€éœ€åº“ï¼Œè®°å½•ç‰ˆæœ¬å…¼å®¹æ€§
try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False

try:
    import torch
    import torch.nn.functional as F
    from transformers import AutoTokenizer, AutoModel
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

from src.code_learner.core.data_models import Function


@dataclass
class EmbeddingModelResult:
    """åµŒå…¥æ¨¡å‹æµ‹è¯•ç»“æœ"""
    model_name: str
    embedding_dim: int
    load_time: float
    encode_time: float
    memory_usage: float
    embedding_quality_score: float
    success: bool
    error_message: str = ""


class TestQwen3EmbeddingPathfinding:
    """Qwen3åµŒå…¥æ¨¡å‹è·¯å¾„æ¢ç´¢æµ‹è¯•ç±»"""
    
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.test_functions = self.create_test_functions()
        self.test_texts = self.create_test_texts()
        self.results = {}
    
    def create_test_functions(self) -> List[Function]:
        """åˆ›å»ºæµ‹è¯•ç”¨çš„Cè¯­è¨€å‡½æ•°"""
        return [
            Function(
                name="quicksort",
                file_path="algorithms/sort.c",
                start_line=1,
                end_line=15,
                code="""void quicksort(int arr[], int low, int high) {
    if (low < high) {
        int pi = partition(arr, low, high);
        quicksort(arr, low, pi - 1);
        quicksort(arr, pi + 1, high);
    }
}"""
            ),
            Function(
                name="binary_search",
                file_path="algorithms/search.c", 
                start_line=1,
                end_line=12,
                code="""int binary_search(int arr[], int n, int target) {
    int left = 0, right = n - 1;
    while (left <= right) {
        int mid = left + (right - left) / 2;
        if (arr[mid] == target) return mid;
        if (arr[mid] < target) left = mid + 1;
        else right = mid - 1;
    }
    return -1;
}"""
            )
        ]
    
    def create_test_texts(self) -> List[str]:
        """åˆ›å»ºæµ‹è¯•æ–‡æœ¬ï¼ŒåŒ…å«ç¼–ç¨‹ç›¸å…³å†…å®¹"""
        return [
            "implement quicksort algorithm in C language",
            "binary search function with array parameter", 
            "linked list insertion operation",
            "matrix multiplication implementation",
            "æ•°æ®ç»“æ„ä¸ç®—æ³•å®ç°",
            "æŒ‡é’ˆæ“ä½œå’Œå†…å­˜ç®¡ç†"
        ]
    
    def test_dependency_check(self):
        """æµ‹è¯•ä¾èµ–åº“ç‰ˆæœ¬æ£€æŸ¥"""
        print("\n=== ä¾èµ–åº“ç‰ˆæœ¬æ£€æŸ¥ ===")
        
        # æ£€æŸ¥sentence-transformers
        if SENTENCE_TRANSFORMERS_AVAILABLE:
            import sentence_transformers
            print(f"âœ… sentence-transformers: {sentence_transformers.__version__}")
        else:
            print("âŒ sentence-transformers: æœªå®‰è£…")
        
        # æ£€æŸ¥transformers
        if TRANSFORMERS_AVAILABLE:
            import transformers
            print(f"âœ… transformers: {transformers.__version__}")
        else:
            print("âŒ transformers: æœªå®‰è£…")
    
    @pytest.mark.skipif(not SENTENCE_TRANSFORMERS_AVAILABLE, reason="sentence-transformers not available")
    def test_qwen3_sentence_transformers_loading(self) -> EmbeddingModelResult:
        """æµ‹è¯•Qwen3æ¨¡å‹ä½¿ç”¨sentence-transformersåŠ è½½"""
        model_name = "Qwen/Qwen3-Embedding-0.6B"
        start_time = time.time()
        
        try:
            # æµ‹è¯•æ¨¡å‹åŠ è½½
            model = SentenceTransformer(model_name)
            load_time = time.time() - start_time
            
            # æµ‹è¯•ç¼–ç åŠŸèƒ½
            start_encode = time.time()
            embeddings = model.encode(self.test_texts[:3])
            encode_time = time.time() - start_encode
            
            # éªŒè¯åµŒå…¥ç»´åº¦
            embedding_dim = len(embeddings[0]) if len(embeddings) > 0 else 0
            
            # è®¡ç®—è´¨é‡åˆ†æ•°ï¼ˆåŸºäºç›¸ä¼¼æ€§ä¸€è‡´æ€§ï¼‰
            quality_score = self.calculate_embedding_quality(embeddings, self.test_texts[:3])
            
            result = EmbeddingModelResult(
                model_name=model_name,
                embedding_dim=embedding_dim,
                load_time=load_time,
                encode_time=encode_time,
                memory_usage=0.0,
                embedding_quality_score=quality_score,
                success=True
            )
            
            print(f"âœ… Qwen3 (sentence-transformers) åŠ è½½æˆåŠŸ")
            print(f"   åµŒå…¥ç»´åº¦: {embedding_dim}")
            print(f"   åŠ è½½æ—¶é—´: {load_time:.2f}ç§’")
            print(f"   ç¼–ç æ—¶é—´: {encode_time:.2f}ç§’")
            
            return result
            
        except Exception as e:
            result = EmbeddingModelResult(
                model_name=model_name,
                embedding_dim=0,
                load_time=time.time() - start_time,
                encode_time=0.0,
                memory_usage=0.0,
                embedding_quality_score=0.0,
                success=False,
                error_message=str(e)
            )
            print(f"âŒ Qwen3 (sentence-transformers) åŠ è½½å¤±è´¥: {str(e)}")
            return result
    
    def test_jina_model_baseline(self) -> EmbeddingModelResult:
        """æµ‹è¯•å½“å‰jinaæ¨¡å‹ä½œä¸ºåŸºå‡†"""
        model_name = "jinaai/jina-embeddings-v2-base-code"
        start_time = time.time()
        
        try:
            if SENTENCE_TRANSFORMERS_AVAILABLE:
                model = SentenceTransformer(model_name)
                load_time = time.time() - start_time
                
                start_encode = time.time()
                embeddings = model.encode(self.test_texts[:3])
                encode_time = time.time() - start_encode
                
                embedding_dim = len(embeddings[0]) if len(embeddings) > 0 else 0
                quality_score = self.calculate_embedding_quality(embeddings, self.test_texts[:3])
                
                result = EmbeddingModelResult(
                    model_name=model_name,
                    embedding_dim=embedding_dim,
                    load_time=load_time,
                    encode_time=encode_time,
                    memory_usage=0.0,
                    embedding_quality_score=quality_score,
                    success=True
                )
                
                print(f"âœ… JinaåŸºå‡†æ¨¡å‹åŠ è½½æˆåŠŸ")
                print(f"   åµŒå…¥ç»´åº¦: {embedding_dim}")
                print(f"   åŠ è½½æ—¶é—´: {load_time:.2f}ç§’")
                print(f"   ç¼–ç æ—¶é—´: {encode_time:.2f}ç§’")
                
                return result
            else:
                raise ImportError("sentence-transformers not available")
                
        except Exception as e:
            result = EmbeddingModelResult(
                model_name=model_name,
                embedding_dim=0,
                load_time=time.time() - start_time,
                encode_time=0.0,
                memory_usage=0.0,
                embedding_quality_score=0.0,
                success=False,
                error_message=str(e)
            )
            print(f"âŒ JinaåŸºå‡†æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            return result
    
    def calculate_embedding_quality(self, embeddings: List[List[float]], texts: List[str]) -> float:
        """è®¡ç®—åµŒå…¥è´¨é‡åˆ†æ•°ï¼ˆåŸºäºç›¸ä¼¼æ€§ä¸€è‡´æ€§ï¼‰"""
        if len(embeddings) < 2:
            return 0.0
        
        try:
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            emb_array = np.array(embeddings)
            
            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦çŸ©é˜µ
            similarities = np.dot(emb_array, emb_array.T) / (
                np.linalg.norm(emb_array, axis=1)[:, np.newaxis] * 
                np.linalg.norm(emb_array, axis=1)[np.newaxis, :]
            )
            
            # è®¡ç®—å¯¹è§’çº¿ï¼ˆè‡ªç›¸ä¼¼åº¦ï¼‰åº”è¯¥æ¥è¿‘1
            diagonal_quality = np.mean(np.diag(similarities))
            
            # è®¡ç®—éå¯¹è§’çº¿å…ƒç´ çš„æ–¹å·®ï¼ˆåŒºåˆ†åº¦ï¼‰
            off_diagonal = similarities[np.triu_indices(len(similarities), k=1)]
            discrimination = 1.0 - np.var(off_diagonal) if len(off_diagonal) > 0 else 0.5
            
            # ç»¼åˆè´¨é‡åˆ†æ•°
            quality_score = (diagonal_quality + discrimination) / 2
            return float(quality_score)
            
        except Exception:
            return 0.0
    
    def test_comparison_models(self):
        """å¯¹æ¯”æµ‹è¯•ï¼šQwen3 vs Jinaæ¨¡å‹"""
        print("\n=== Qwen3 vs Jina æ¨¡å‹å¯¹æ¯”æµ‹è¯• ===")
        
        # æµ‹è¯•JinaåŸºå‡†æ¨¡å‹
        print("æµ‹è¯•JinaåŸºå‡†æ¨¡å‹...")
        jina_result = self.test_jina_model_baseline()
        self.results['jina'] = jina_result
        
        # æµ‹è¯•Qwen3 (sentence-transformers)
        print("\næµ‹è¯•Qwen3æ¨¡å‹...")
        qwen3_result = self.test_qwen3_sentence_transformers_loading()
        self.results['qwen3'] = qwen3_result
        
        # æ‰“å°å¯¹æ¯”ç»“æœ
        self.print_comparison_results()
        
        # ç”Ÿæˆè¿ç§»å»ºè®®
        self.generate_migration_recommendation()
    
    def print_comparison_results(self):
        """æ‰“å°å¯¹æ¯”ç»“æœ"""
        print("\n=== æ¨¡å‹å¯¹æ¯”ç»“æœ ===")
        
        for model_key, result in self.results.items():
            print(f"\n{result.model_name}:")
            print(f"  æˆåŠŸåŠ è½½: {'âœ…' if result.success else 'âŒ'}")
            
            if result.success:
                print(f"  åµŒå…¥ç»´åº¦: {result.embedding_dim}")
                print(f"  åŠ è½½æ—¶é—´: {result.load_time:.2f}ç§’")
                print(f"  ç¼–ç æ—¶é—´: {result.encode_time:.2f}ç§’")
                print(f"  è´¨é‡åˆ†æ•°: {result.embedding_quality_score:.3f}")
            else:
                print(f"  é”™è¯¯ä¿¡æ¯: {result.error_message}")
    
    def generate_migration_recommendation(self):
        """ç”Ÿæˆè¿ç§»å»ºè®®æŠ¥å‘Š"""
        print("\n=== è¿ç§»å»ºè®®æŠ¥å‘Š ===")
        
        jina_success = self.results.get('jina', EmbeddingModelResult("", 0, 0, 0, 0, 0, False)).success
        qwen3_success = self.results.get('qwen3', EmbeddingModelResult("", 0, 0, 0, 0, 0, False)).success
        
        print(f"å½“å‰Jinaæ¨¡å‹çŠ¶æ€: {'âœ… æ­£å¸¸å·¥ä½œ' if jina_success else 'âŒ å­˜åœ¨é—®é¢˜'}")
        print(f"Qwen3æ¨¡å‹çŠ¶æ€: {'âœ… å¯ç”¨' if qwen3_success else 'âŒ ä¸å¯ç”¨'}")
        
        if qwen3_success:
            qwen3_result = self.results['qwen3']
            print(f"\nâœ… å»ºè®®è¿ç§»åˆ°Qwen3-Embedding-0.6Bæ¨¡å‹")
            print(f"ç†ç”±ï¼š")
            print(f"  - åµŒå…¥ç»´åº¦æå‡ï¼š{qwen3_result.embedding_dim}ç»´ (vs 768ç»´)")
            print(f"  - é¢„æœŸæ€§èƒ½æå‡ï¼š10-15%")
            print(f"  - æ”¯æŒæ›´å¤šè¯­è¨€å’Œç¼–ç¨‹è¯­è¨€")
            print(f"  - æ”¯æŒæŒ‡ä»¤æ„ŸçŸ¥ä¼˜åŒ–")
            
            print(f"\néœ€è¦çš„å˜æ›´ï¼š")
            print(f"  - æ›´æ–°transformersåº“åˆ°>=4.51.0ç‰ˆæœ¬")
            print(f"  - è°ƒæ•´å‘é‡å­˜å‚¨ä»¥æ”¯æŒ{qwen3_result.embedding_dim}ç»´åµŒå…¥")
            print(f"  - æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹æ ‡è¯†ç¬¦")
            print(f"  - é‡æ–°å»ºç«‹å‘é‡ç´¢å¼•")
            
            print(f"\né£é™©è¯„ä¼°ï¼š")
            print(f"  âš ï¸  åµŒå…¥ç»´åº¦å˜åŒ–éœ€è¦é‡æ–°å»ºç«‹å‘é‡ç´¢å¼•")
            print(f"  âš ï¸  éœ€è¦éªŒè¯ä¸Chromaå‘é‡å­˜å‚¨çš„å…¼å®¹æ€§")
            print(f"  âš ï¸  æ¨¡å‹é¦–æ¬¡åŠ è½½å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´")
        else:
            print(f"\nâŒ æš‚ä¸å»ºè®®è¿ç§»")
            print(f"åŸå› ï¼šQwen3æ¨¡å‹åŠ è½½å¤±è´¥")
            if 'qwen3' in self.results:
                print(f"é”™è¯¯ä¿¡æ¯: {self.results['qwen3'].error_message}")
            print(f"å»ºè®®ï¼šè§£å†³ä¾èµ–é—®é¢˜åé‡æ–°è¯„ä¼°")


if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œæµ‹è¯•
    test_instance = TestQwen3EmbeddingPathfinding()
    test_instance.setup_method()
    
    print("ğŸ” Qwen3-Embedding-0.6B è·¯å¾„æ¢ç´¢æµ‹è¯•å¼€å§‹...")
    
    test_instance.test_dependency_check()
    test_instance.test_comparison_models()
    
    print("\nâœ… è·¯å¾„æ¢ç´¢æµ‹è¯•å®Œæˆï¼") 